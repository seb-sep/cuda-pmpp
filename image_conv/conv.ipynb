{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/seb/.cache/torch_extensions/py312_cu121 as PyTorch extensions root...\n",
      "The input conditions for extension module m have changed. Bumping to version 6 and re-building as m_v6...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/seb/.cache/torch_extensions/py312_cu121/m/build.ninja...\n",
      "/home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module m_v6...\n",
      "Using envvar MAX_JOBS (16) as the number of workers...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/4] c++ -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=m_v6 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include/TH -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include/THC -isystem /usr/local/cuda-12.3/include -isystem /home/seb/miniconda3/include/python3.12 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /home/seb/CUDA/pmpp/image_conv/main.cpp -o main.o \n",
      "[2/4] /usr/local/cuda-12.3/bin/nvcc --generate-dependencies-with-compile --dependency-output conv_2d.cuda.o.d -DTORCH_EXTENSION_NAME=m_v6 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include/TH -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include/THC -isystem /usr/local/cuda-12.3/include -isystem /home/seb/miniconda3/include/python3.12 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_61,code=compute_61 -gencode=arch=compute_61,code=sm_61 --compiler-options '-fPIC' -std=c++17 -c /home/seb/CUDA/pmpp/image_conv/conv_2d.cu -o conv_2d.cuda.o \n",
      "[3/4] /usr/local/cuda-12.3/bin/nvcc --generate-dependencies-with-compile --dependency-output conv_1d.cuda.o.d -DTORCH_EXTENSION_NAME=m_v6 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include/TH -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include/THC -isystem /usr/local/cuda-12.3/include -isystem /home/seb/miniconda3/include/python3.12 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_61,code=compute_61 -gencode=arch=compute_61,code=sm_61 --compiler-options '-fPIC' -std=c++17 -c /home/seb/CUDA/pmpp/image_conv/conv_1d.cu -o conv_1d.cuda.o \n",
      "[4/4] c++ conv_1d.cuda.o conv_2d.cuda.o main.o -shared -L/home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda-12.3/lib64 -lcudart -o m_v6.so\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module m_v6...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.cpp_extension import load\n",
    "os.environ['MAX_JOBS'] = '16'\n",
    "module = load(\n",
    "    name='m',\n",
    "    sources=['conv_1d.cu', 'conv_2d.cu', 'main.cpp'],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# a = torch.tensor([1.0, 2.0, 3.0, 4.0, 5], dtype=torch.float32, device='cuda')\n",
    "# mask = torch.tensor([0.0, 1.0, 0.0], dtype=torch.float32, device='cuda')\n",
    "a = torch.rand(512, device='cuda', dtype=torch.float32)\n",
    "mask_size = 5\n",
    "mask = torch.rand(mask_size, device='cuda', dtype=torch.float32)\n",
    "\n",
    "\n",
    "torch_res = F.conv1d(a.unsqueeze(0).unsqueeze(0), mask.unsqueeze(0).unsqueeze(0), padding=mask_size//2).flatten()\n",
    "my_res = module.conv1d(a, mask).flatten()\n",
    "\n",
    "print(torch.allclose(my_res, torch_res))\n",
    "# my_res, torch_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.9701, 1.4021, 1.3976,  ..., 1.5615, 1.2028, 1.2654],\n",
       "           [1.4884, 2.0791, 2.0830,  ..., 2.7148, 2.0361, 2.3480],\n",
       "           [1.7177, 2.7809, 3.1708,  ..., 2.7130, 2.1817, 1.8365],\n",
       "           ...,\n",
       "           [0.8189, 2.3894, 2.2781,  ..., 2.6227, 2.3632, 1.3460],\n",
       "           [1.2466, 2.4315, 2.3588,  ..., 2.4311, 2.1068, 1.1572],\n",
       "           [1.4461, 1.6468, 1.4968,  ..., 2.0124, 1.4759, 0.6782]]]],\n",
       "        device='cuda:0'),\n",
       " tensor([[0.9701, 1.4021, 1.3976,  ..., 1.5615, 1.2028, 1.2654],\n",
       "         [1.4884, 2.0791, 2.0830,  ..., 2.7148, 2.0361, 2.3480],\n",
       "         [1.7177, 2.7809, 3.1708,  ..., 2.7130, 2.1817, 1.8365],\n",
       "         ...,\n",
       "         [0.8189, 2.3894, 2.2781,  ..., 2.6227, 2.3632, 1.3460],\n",
       "         [1.2466, 2.4315, 2.3588,  ..., 2.4311, 2.1068, 1.1572],\n",
       "         [1.4461, 1.6468, 1.4968,  ..., 2.0124, 1.4759, 0.6782]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.rand((512, 512), device='cuda', dtype=torch.float32)\n",
    "mask_size = (3, 3)\n",
    "mask = torch.rand(mask_size, device='cuda', dtype=torch.float32)\n",
    "# b = torch.ones((3, 3), device='cuda', dtype=torch.float32)\n",
    "# mask = torch.ones((3, 3), device='cuda', dtype=torch.float32)\n",
    "# mask = torch.tensor([[0, 1, 0], \n",
    "#                      [1, 0, 1], \n",
    "#                      [0, 1, 0]], device='cuda', dtype=torch.float32)\n",
    "\n",
    "torch_res = F.conv2d(b.unsqueeze(0).unsqueeze(0), mask.unsqueeze(0).unsqueeze(0), padding=mask_size[0]//2)\n",
    "my_res = module.conv2d(b, mask)\n",
    "print(torch.allclose(torch_res, my_res))\n",
    "torch_res, my_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
