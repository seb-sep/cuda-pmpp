{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def unroll(X: torch.Tensor, k: int, h_out: int, w_out: int):\n",
    "    \"\"\"\n",
    "    Unroll input values into the shape required by weight dims and output dims.\n",
    "    Assume X is only a single sample.\n",
    "    \"\"\"\n",
    "    C = X.shape[0]\n",
    "    X_unrolled = torch.empty((C*k*k, h_out*w_out), dtype=int)\n",
    "\n",
    "    # think of the iteration as the stamping out of the conv mask\n",
    "    for c, p, q, h, w in product(*(range(C), range(k), range(k), range(h_out), range(w_out))):\n",
    "        \n",
    "        # the c*k*k tells you which channel you're currently on in the column\n",
    "        # p*k + q tells you which value you're in for a single weight mas\n",
    "        h_unroll = c*k*k + p*k + q\n",
    "        # w_unroll tells you which column you're operating on, which corresponds to \n",
    "        # the unrolled index into the output matrix\n",
    "        w_unroll = h * w_out + w\n",
    "        X_unrolled[h_unroll, w_unroll] = X[c, h+p, w+q]\n",
    "\n",
    "    return X_unrolled\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def conv2d(X: torch.Tensor, W_unroll: torch.Tensor, k: int):\n",
    "    # X is (N, C, H, W)\n",
    "    N, C, H, W = X.shape\n",
    "\n",
    "    # W is (M, C*k*k)\n",
    "    M = W_unroll.shape[0]\n",
    "\n",
    "    h_out = H - k + 1\n",
    "    w_out = W - k + 1\n",
    "    # don't forget the extra first batch size dim\n",
    "    Y = torch.empty((N, M, h_out*w_out))\n",
    "\n",
    "    for n in range(N):\n",
    "        X_unrolled = unroll(X[n], k, h_out, w_out)\n",
    "        Y[n] = W_unroll @ X_unrolled\n",
    "\n",
    "    return Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 1, 1],\n",
       "        [2, 0, 1, 3],\n",
       "        [1, 1, 0, 2],\n",
       "        [1, 3, 2, 2],\n",
       "        [0, 2, 0, 3],\n",
       "        [2, 1, 3, 2],\n",
       "        [0, 3, 1, 1],\n",
       "        [3, 2, 1, 0],\n",
       "        [1, 2, 0, 1],\n",
       "        [2, 1, 1, 3],\n",
       "        [0, 1, 3, 3],\n",
       "        [1, 3, 3, 2]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_unroll = torch.tensor([[1, 1, 2, 2, 1, 1, 1, 1, 0, 1, 1, 0],\n",
    "        [1, 0, 0, 1, 2, 1, 2, 1, 1, 2, 2, 0]], dtype=torch.float32)\n",
    "\n",
    "X = torch.tensor([[[1, 2, 0],\n",
    "         [1, 1, 3],\n",
    "         [0, 2, 2]],\n",
    "\n",
    "        [[0, 2, 1],\n",
    "         [0, 3, 2],\n",
    "         [1, 1, 0]],\n",
    "\n",
    "        [[1, 2, 1],\n",
    "         [0, 1, 3],\n",
    "         [3, 3, 2]]], dtype=torch.float32, device='cuda')\n",
    "\n",
    "unroll(X, 2, 2, 2)\n",
    "\n",
    "# unsqueeze for the batch size of 1\n",
    "# conv2d(X.unsqueeze(0), w_unroll, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/seb/.cache/torch_extensions/py312_cu121 as PyTorch extensions root...\n",
      "The input conditions for extension module m have changed. Bumping to version 10 and re-building as m_v10...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/seb/.cache/torch_extensions/py312_cu121/m/build.ninja...\n",
      "/home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module m_v10...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] c++ -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=m_v10 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include/TH -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include/THC -isystem /usr/local/cuda-12.3/include -isystem /home/seb/miniconda3/include/python3.12 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /home/seb/CUDA/pmpp/cnn/main.cpp -o main.o \n",
      "[2/3] /usr/local/cuda-12.3/bin/nvcc --generate-dependencies-with-compile --dependency-output cnn2d.cuda.o.d -DTORCH_EXTENSION_NAME=m_v10 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include/TH -isystem /home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/include/THC -isystem /usr/local/cuda-12.3/include -isystem /home/seb/miniconda3/include/python3.12 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_61,code=compute_61 -gencode=arch=compute_61,code=sm_61 --compiler-options '-fPIC' -std=c++17 -c /home/seb/CUDA/pmpp/cnn/cnn2d.cu -o cnn2d.cuda.o \n",
      "[3/3] c++ main.o cnn2d.cuda.o -shared -L/home/seb/CUDA/cudaenv/lib/python3.12/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda-12.3/lib64 -lcudart -o m_v10.so\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module m_v10...\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.cpp_extension import load\n",
    "module = load(\n",
    "    name='m',\n",
    "    sources=['main.cpp', 'cnn2d.cu'],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 threads, 1 blocks, \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 1., 1.],\n",
       "        [2., 0., 1., 3.],\n",
       "        [1., 1., 0., 2.],\n",
       "        [1., 3., 2., 2.],\n",
       "        [0., 2., 0., 3.],\n",
       "        [2., 1., 3., 2.],\n",
       "        [0., 3., 1., 1.],\n",
       "        [3., 2., 1., 0.],\n",
       "        [1., 2., 0., 1.],\n",
       "        [2., 1., 1., 3.],\n",
       "        [0., 1., 3., 3.],\n",
       "        [1., 3., 3., 2.]], device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = module.unroll(X, 2)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
